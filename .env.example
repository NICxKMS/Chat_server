# Server Configuration
PORT=3000
NODE_ENV=development

# Default Provider
DEFAULT_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_BASE_URL=https://api.anthropic.com

# Google Gemini Configuration
GOOGLE_API_KEY=your-google-api-key

# OpenRouter Configuration
# OpenRouter now uses Clerk authentication - use the format "sk-or-v1-..." from your OpenRouter dashboard
OPENROUTER_API_KEY=sk-or-v1-your-openrouter-api-key
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# Optional OpenRouter configs
OPENROUTER_HTTP_REFERER=https://your-app-domain.com # Identifies your app to models (required by OpenRouter)
OPENROUTER_TITLE=Your App Name # Optional title shown in OpenRouter dashboard

# Cache Configuration
# Set to 'true' to enable Redis caching (if available)
USE_REDIS_CACHE=false
REDIS_URL=redis://localhost:6379
MEMORY_CACHE_TTL=300 # Time to live in seconds for memory cache (5 minutes)
REDIS_CACHE_TTL=1800 # Time to live in seconds for Redis cache (30 minutes)

# Performance & Scaling
RESPONSE_TIMEOUT=30000 # Maximum response time in milliseconds
MAX_REQUEST_SIZE=1MB # Maximum request body size
DYNAMIC_MODEL_LOADING=true # Whether to dynamically load model lists from providers
REQUEST_RATE_LIMIT=100 # Maximum requests per minute per IP
CONCURRENT_REQUEST_LIMIT=20 # Maximum concurrent requests per IP